{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20edee2e-715c-4a03-90b2-1372ffc7516e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:10:51.478498Z",
     "iopub.status.busy": "2024-04-17T16:10:51.477624Z",
     "iopub.status.idle": "2024-04-17T16:10:59.958456Z",
     "shell.execute_reply": "2024-04-17T16:10:59.956976Z",
     "shell.execute_reply.started": "2024-04-17T16:10:51.478441Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/jupyter/.local/lib/python3.10/site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /kernel/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /kernel/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /kernel/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /kernel/lib/python3.10/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae44fd12-d415-416d-86ea-c589bb282c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:12:20.552616Z",
     "iopub.status.busy": "2024-04-17T16:12:20.551710Z",
     "iopub.status.idle": "2024-04-17T16:12:21.018069Z",
     "shell.execute_reply": "2024-04-17T16:12:21.017014Z",
     "shell.execute_reply.started": "2024-04-17T16:12:20.552563Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected IDs for removal: [28250406 27130218 19009665 27773410 26457578]\n",
      "Количество уникальных значений: 82\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data_path = \"processed_entities_tokenized.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df['Sent_ID'] = df['Text_ID'].astype(str) + '-' + df['Sent_ID'].astype(str)\n",
    "\n",
    "ids_to_remove = [19214295, 20146086, 25139918, 25410883, 25853982, 26469535, 27218632, 27793101, 28120581, 28250304]\n",
    "df = df[~df['Text_ID'].isin(ids_to_remove)]\n",
    "remaining_ids = df['Text_ID'].unique()\n",
    "random_ids = np.random.choice(remaining_ids, size=5, replace=False)\n",
    "print(\"Randomly selected IDs for removal:\", random_ids)\n",
    "df = df[~df['Text_ID'].isin(random_ids)]\n",
    "\n",
    "sentences = df.groupby('Sent_ID')['Token'].apply(list).values\n",
    "labels = df.groupby('Sent_ID')['Label'].apply(list).values\n",
    "\n",
    "unique_labels = set(label for sublist in labels for label in sublist)\n",
    "num_unique_labels = len(unique_labels)\n",
    "print(\"Количество уникальных значений:\", num_unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55de9fb-8d3d-4520-9aab-fe64936924f9",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f703ff6-a025-46d3-9de3-a600d5120490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:23:05.259832Z",
     "iopub.status.busy": "2024-04-17T16:23:05.259040Z",
     "iopub.status.idle": "2024-04-17T16:23:06.541050Z",
     "shell.execute_reply": "2024-04-17T16:23:06.539808Z",
     "shell.execute_reply.started": "2024-04-17T16:23:05.259798Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_flatten = label_encoder.fit_transform([item for sublist in labels for item in sublist])\n",
    "labels_encoded = [label_encoder.transform(label).tolist() for label in labels]\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "tokenized_input = tokenizer(sentences.tolist(), is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fc1b4eb-7262-4376-8d8d-641da207beb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:23:06.544136Z",
     "iopub.status.busy": "2024-04-17T16:23:06.543171Z",
     "iopub.status.idle": "2024-04-17T16:23:06.561568Z",
     "shell.execute_reply": "2024-04-17T16:23:06.560481Z",
     "shell.execute_reply.started": "2024-04-17T16:23:06.544083Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "label_encoder_path = \"label_encoder.joblib\"\n",
    "joblib.dump(label_encoder, label_encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94cf6206-ef2a-48e4-b1c5-4958b89eb7f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:23:06.563780Z",
     "iopub.status.busy": "2024-04-17T16:23:06.563244Z",
     "iopub.status.idle": "2024-04-17T16:23:06.619642Z",
     "shell.execute_reply": "2024-04-17T16:23:06.618483Z",
     "shell.execute_reply.started": "2024-04-17T16:23:06.563747Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, tokenized_input):\n",
    "    labels_aligned = []\n",
    "    for i, label in enumerate(labels):\n",
    "        word_ids = tokenized_input.word_ids(batch_index=i)\n",
    "        label_aligned = [-100 if word_id is None else label[word_id] for word_id in word_ids]\n",
    "        labels_aligned.append(label_aligned)\n",
    "    return labels_aligned\n",
    "\n",
    "labels_aligned = align_labels_with_tokens(labels_encoded, tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c354d950-dcd7-41e9-8fef-165ef09579f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:23:10.810683Z",
     "iopub.status.busy": "2024-04-17T16:23:10.809838Z",
     "iopub.status.idle": "2024-04-17T16:23:10.829198Z",
     "shell.execute_reply": "2024-04-17T16:23:10.828096Z",
     "shell.execute_reply.started": "2024-04-17T16:23:10.810647Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenized_inputs, labels_aligned):\n",
    "        self.tokenized_inputs = tokenized_inputs\n",
    "        self.labels = labels_aligned\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_inputs.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(tokenized_input, labels_aligned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec2fba6e-7e6b-46ca-b748-34672e03ecf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:23:11.819869Z",
     "iopub.status.busy": "2024-04-17T16:23:11.818927Z",
     "iopub.status.idle": "2024-04-17T16:23:11.885900Z",
     "shell.execute_reply": "2024-04-17T16:23:11.884122Z",
     "shell.execute_reply.started": "2024-04-17T16:23:11.819830Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e32d784-6225-4616-a5d4-f89484d75c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:23:14.346107Z",
     "iopub.status.busy": "2024-04-17T16:23:14.345076Z",
     "iopub.status.idle": "2024-04-17T16:23:15.383090Z",
     "shell.execute_reply": "2024-04-17T16:23:15.382050Z",
     "shell.execute_reply.started": "2024-04-17T16:23:14.346073Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=82, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, AdamW\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(label_encoder.classes_),\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57af3414-376f-4f2a-9418-40f5e2eba3cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:23:16.514833Z",
     "iopub.status.busy": "2024-04-17T16:23:16.513766Z",
     "iopub.status.idle": "2024-04-17T16:28:46.495131Z",
     "shell.execute_reply": "2024-04-17T16:28:46.493749Z",
     "shell.execute_reply.started": "2024-04-17T16:23:16.514784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.7246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.5023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.3437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.2431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.1783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.1294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 10\n",
    "total_steps = len(train_loader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(data_loader, desc='Batch', leave=False)\n",
    "    for batch in progress_bar:\n",
    "        if 'offset_mapping' in batch:\n",
    "            del batch['offset_mapping']\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = train_epoch(model, train_loader, optimizer, device, scheduler)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a49bc31c-47ec-4d6e-8fcf-34da6aaf43ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:28:46.497575Z",
     "iopub.status.busy": "2024-04-17T16:28:46.496899Z",
     "iopub.status.idle": "2024-04-17T16:28:46.538329Z",
     "shell.execute_reply": "2024-04-17T16:28:46.537238Z",
     "shell.execute_reply.started": "2024-04-17T16:28:46.497524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: O\n",
      "a: O\n",
      "20: B-Age\n",
      "-: I-Age\n",
      "year: I-Age\n",
      "-: I-Age\n",
      "old: I-Age\n",
      "woman: B-Sex\n",
      "was: O\n",
      "diagnosed: B-Clinical_event\n",
      "with: O\n",
      "breast: B-Disease_disorder\n",
      "cancer: I-Disease_disorder\n",
      "[SEP]: O\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "text = \"A 20-year-old woman was diagnosed with breast cancer\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "predicted_label_indices = predictions.squeeze().cpu().numpy()\n",
    "\n",
    "predicted_labels = [label_encoder.inverse_transform([idx])[0] for idx in predicted_label_indices]\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].cpu())\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f0bb5-9759-47d5-9492-77b3134b21cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abadbfb5-aebf-4b61-a807-dd423e3418b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:28:46.541074Z",
     "iopub.status.busy": "2024-04-17T16:28:46.540363Z",
     "iopub.status.idle": "2024-04-17T16:28:46.553764Z",
     "shell.execute_reply": "2024-04-17T16:28:46.552681Z",
     "shell.execute_reply.started": "2024-04-17T16:28:46.541041Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"A 28-year-old previously healthy man presented with a 6-week history of palpitations. The symptoms occurred during rest, 2–3 times per week, lasted up to 30 minutes at a time and were associated with dyspnea.Except for a grade 2/6 holosystolic tricuspid regurgitation murmur (best heard at the left sternal border with inspiratory accentuation), physical examination yielded unremarkable findings.An electrocardiogram (ECG) revealed normal sinus rhythm and a Wolff– Parkinson– White pre-excitation pattern (Fig.1: Top), produced by a right-sided accessory pathway.Transthoracic echocardiography demonstrated the presence of Ebstein's anomaly of the tricuspid valve, with apical displacement of the valve and formation of an “atrialized” right ventricle (a functional unit between the right atrium and the inlet [inflow] portion of the right ventricle) (Fig.2).The anterior tricuspid valve leaflet was elongated (Fig.2C, arrow), whereas the septal leaflet was rudimentary (Fig.2C, arrowhead).Contrast echocardiography using saline revealed a patent foramen ovale with right-to-left shunting and bubbles in the left atrium (Fig.2D).The patient underwent an electrophysiologic study with mapping of the accessory pathway, followed by radiofrequency ablation (interruption of the pathway using the heat generated by electromagnetic waves at the tip of an ablation catheter).His post-ablation ECG showed a prolonged PR interval and an odd “second” QRS complex in leads III, aVF and V2–V4 (Fig.1Bottom), a consequence of abnormal impulse conduction in the “atrialized” right ventricle.The patient reported no recurrence of palpitations at follow-up 6 months after the ablation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2058bcb7-7086-466b-81a5-d4226504915e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:28:46.556290Z",
     "iopub.status.busy": "2024-04-17T16:28:46.555399Z",
     "iopub.status.idle": "2024-04-17T16:28:46.639718Z",
     "shell.execute_reply": "2024-04-17T16:28:46.638563Z",
     "shell.execute_reply.started": "2024-04-17T16:28:46.556237Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: O\n",
      "a: O\n",
      "28: B-Age\n",
      "-: I-Age\n",
      "year: I-Age\n",
      "-: I-Age\n",
      "old: I-Age\n",
      "previously: B-History\n",
      "healthy: I-History\n",
      "man: B-Sex\n",
      "presented: B-Clinical_event\n",
      "with: O\n",
      "a: O\n",
      "6: B-Duration\n",
      "-: I-Duration\n",
      "week: I-Duration\n",
      "history: O\n",
      "of: O\n",
      "pal: B-Sign_symptom\n",
      "##pit: B-Sign_symptom\n",
      "##ations: B-Sign_symptom\n",
      ".: O\n",
      "the: O\n",
      "symptoms: B-Sign_symptom\n",
      "occurred: O\n",
      "during: O\n",
      "rest: B-Clinical_event\n",
      ",: O\n",
      "2: B-Frequency\n",
      "–: I-Frequency\n",
      "3: I-Frequency\n",
      "times: I-Frequency\n",
      "per: I-Frequency\n",
      "week: I-Frequency\n",
      ",: O\n",
      "lasted: O\n",
      "up: B-Detailed_description\n",
      "to: I-Detailed_description\n",
      "30: I-Detailed_description\n",
      "minutes: I-Detailed_description\n",
      "at: I-Detailed_description\n",
      "a: I-Frequency\n",
      "time: I-Detailed_description\n",
      "and: O\n",
      "were: O\n",
      "associated: O\n",
      "with: O\n",
      "d: B-Sign_symptom\n",
      "##ys: B-Sign_symptom\n",
      "##p: B-Sign_symptom\n",
      "##nea: B-Sign_symptom\n",
      ".: O\n",
      "except: O\n",
      "for: O\n",
      "a: O\n",
      "grade: B-Lab_value\n",
      "2: I-Lab_value\n",
      "/: I-Lab_value\n",
      "6: I-Lab_value\n",
      "ho: B-Detailed_description\n",
      "##los: B-Detailed_description\n",
      "##yst: B-Detailed_description\n",
      "##olic: B-Detailed_description\n",
      "tri: B-Biological_structure\n",
      "##cus: B-Biological_structure\n",
      "##pid: B-Biological_structure\n",
      "reg: B-Sign_symptom\n",
      "##urg: B-Sign_symptom\n",
      "##itation: B-Sign_symptom\n",
      "murmur: B-Sign_symptom\n",
      "(: O\n",
      "best: O\n",
      "heard: O\n",
      "at: O\n",
      "the: O\n",
      "left: B-Biological_structure\n",
      "stern: I-Biological_structure\n",
      "##al: I-Biological_structure\n",
      "border: I-Biological_structure\n",
      "with: O\n",
      "ins: B-Detailed_description\n",
      "##pi: B-Detailed_description\n",
      "##rator: B-Detailed_description\n",
      "##y: B-Detailed_description\n",
      "accent: I-Detailed_description\n",
      "##uation: I-Detailed_description\n",
      "): O\n",
      ",: O\n",
      "physical: B-Diagnostic_procedure\n",
      "examination: I-Diagnostic_procedure\n",
      "yielded: O\n",
      "un: B-Lab_value\n",
      "##rem: B-Lab_value\n",
      "##ark: B-Lab_value\n",
      "##able: B-Lab_value\n",
      "findings: I-Lab_value\n",
      ".: O\n",
      "an: O\n",
      "electro: B-Diagnostic_procedure\n",
      "##card: B-Diagnostic_procedure\n",
      "##io: B-Diagnostic_procedure\n",
      "##gram: B-Diagnostic_procedure\n",
      "(: O\n",
      "ec: B-Diagnostic_procedure\n",
      "##g: B-Diagnostic_procedure\n",
      "): O\n",
      "revealed: O\n",
      "normal: B-Lab_value\n",
      "sin: B-Diagnostic_procedure\n",
      "##us: B-Diagnostic_procedure\n",
      "rhythm: I-Diagnostic_procedure\n",
      "and: O\n",
      "a: O\n",
      "wolff: B-Sign_symptom\n",
      "–: I-Sign_symptom\n",
      "parkinson: I-Sign_symptom\n",
      "–: I-Sign_symptom\n",
      "white: I-Sign_symptom\n",
      "pre: B-Sign_symptom\n",
      "-: I-Sign_symptom\n",
      "ex: I-Sign_symptom\n",
      "##cit: I-Sign_symptom\n",
      "##ation: I-Sign_symptom\n",
      "pattern: I-Sign_symptom\n",
      "(: O\n",
      "fig: O\n",
      ".: O\n",
      "[SEP]: O\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "predicted_label_indices = predictions.squeeze().cpu().numpy()\n",
    "\n",
    "predicted_labels = [label_encoder.inverse_transform([idx])[0] for idx in predicted_label_indices]\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].cpu())\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7db9a59-0244-4c48-93aa-e49856115ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:28:46.642011Z",
     "iopub.status.busy": "2024-04-17T16:28:46.641157Z",
     "iopub.status.idle": "2024-04-17T16:28:46.672279Z",
     "shell.execute_reply": "2024-04-17T16:28:46.671144Z",
     "shell.execute_reply.started": "2024-04-17T16:28:46.641961Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: O\n",
      "a: O\n",
      "28: B-Age\n",
      "-: I-Age\n",
      "year: I-Age\n",
      "-: I-Age\n",
      "old: I-Age\n",
      "previously: B-History\n",
      "healthy: I-History\n",
      "man: B-Sex\n",
      "presented: B-Clinical_event\n",
      "with: O\n",
      "a: O\n",
      "6: B-Duration\n",
      "-: I-Duration\n",
      "week: I-Duration\n",
      "history: O\n",
      "of: O\n",
      "palpitations: B-Sign_symptom\n",
      ".: O\n",
      "the: O\n",
      "symptoms: B-Sign_symptom\n",
      "occurred: O\n",
      "during: O\n",
      "rest: B-Clinical_event\n",
      ",: O\n",
      "2: B-Frequency\n",
      "–: I-Frequency\n",
      "3: I-Frequency\n",
      "times: I-Frequency\n",
      "per: I-Frequency\n",
      "week: I-Frequency\n",
      ",: O\n",
      "lasted: O\n",
      "up: B-Detailed_description\n",
      "to: I-Detailed_description\n",
      "30: I-Detailed_description\n",
      "minutes: I-Detailed_description\n",
      "at: I-Detailed_description\n",
      "a: I-Frequency\n",
      "time: I-Detailed_description\n",
      "and: O\n",
      "were: O\n",
      "associated: O\n",
      "with: O\n",
      "dyspnea: B-Sign_symptom\n",
      ".: O\n",
      "except: O\n",
      "for: O\n",
      "a: O\n",
      "grade: B-Lab_value\n",
      "2: I-Lab_value\n",
      "/: I-Lab_value\n",
      "6: I-Lab_value\n",
      "holosystolic: B-Detailed_description\n",
      "tricuspid: B-Biological_structure\n",
      "regurgitation: B-Sign_symptom\n",
      "murmur: B-Sign_symptom\n",
      "(: O\n",
      "best: O\n",
      "heard: O\n",
      "at: O\n",
      "the: O\n",
      "left: B-Biological_structure\n",
      "sternal: I-Biological_structure\n",
      "border: I-Biological_structure\n",
      "with: O\n",
      "inspiratory: B-Detailed_description\n",
      "accentuation: I-Detailed_description\n",
      "): O\n",
      ",: O\n",
      "physical: B-Diagnostic_procedure\n",
      "examination: I-Diagnostic_procedure\n",
      "yielded: O\n",
      "unremarkable: B-Lab_value\n",
      "findings: I-Lab_value\n",
      ".: O\n",
      "an: O\n",
      "electrocardiogram: B-Diagnostic_procedure\n",
      "(: O\n",
      "ecg: B-Diagnostic_procedure\n",
      "): O\n",
      "revealed: O\n",
      "normal: B-Lab_value\n",
      "sinus: B-Diagnostic_procedure\n",
      "rhythm: I-Diagnostic_procedure\n",
      "and: O\n",
      "a: O\n",
      "wolff: B-Sign_symptom\n",
      "–: I-Sign_symptom\n",
      "parkinson: I-Sign_symptom\n",
      "–: I-Sign_symptom\n",
      "white: I-Sign_symptom\n",
      "pre: B-Sign_symptom\n",
      "-: I-Sign_symptom\n",
      "excitation: I-Sign_symptom\n",
      "pattern: I-Sign_symptom\n",
      "(: O\n",
      "fig: O\n",
      ".: O\n",
      "[SEP]: O\n"
     ]
    }
   ],
   "source": [
    "word_labels = []\n",
    "current_word = \"\"\n",
    "current_label = None\n",
    "\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    if token.startswith(\"##\"):\n",
    "        current_word += token[2:]\n",
    "    else:\n",
    "        if current_word:\n",
    "            word_labels.append((current_word, current_label))\n",
    "        current_word = token\n",
    "        current_label = label\n",
    "\n",
    "if current_word:\n",
    "    word_labels.append((current_word, current_label))\n",
    "\n",
    "for word, label in word_labels:\n",
    "    print(f\"{word}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dcc8d45-61cd-48f0-babc-08c41e9c1c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:18:54.828450Z",
     "iopub.status.busy": "2024-04-17T16:18:54.827491Z",
     "iopub.status.idle": "2024-04-17T16:18:58.272191Z",
     "shell.execute_reply": "2024-04-17T16:18:58.271131Z",
     "shell.execute_reply.started": "2024-04-17T16:18:54.828410Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('without_anomalies_bert_model/tokenizer_config.json',\n",
       " 'without_anomalies_bert_model/special_tokens_map.json',\n",
       " 'without_anomalies_bert_model/vocab.txt',\n",
       " 'without_anomalies_bert_model/added_tokens.json',\n",
       " 'without_anomalies_bert_model/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"without_anomalies_bert_model\"\n",
    "\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac138cb-fdc5-433e-8e78-742fbb664522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb709f60-b4cb-4c94-9f71-3823a64a08d5",
   "metadata": {},
   "source": [
    "# Общая часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0db2934a-8ebc-4b6f-aa9c-2bedd546e24c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:28:46.674720Z",
     "iopub.status.busy": "2024-04-17T16:28:46.673826Z",
     "iopub.status.idle": "2024-04-17T16:28:46.691505Z",
     "shell.execute_reply": "2024-04-17T16:28:46.690400Z",
     "shell.execute_reply.started": "2024-04-17T16:28:46.674655Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_model_and_tokenizer(model_name, num_labels):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    return tokenizer, model\n",
    "\n",
    "def load_and_prepare_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['Sent_ID'] = df['Text_ID'].astype(str) + '-' + df['Sent_ID'].astype(str)\n",
    "    sentences = df.groupby('Sent_ID')['Token'].apply(list).values\n",
    "    labels = df.groupby('Sent_ID')['Label'].apply(list).values\n",
    "    unique_labels = set(label for sublist in labels for label in sublist)\n",
    "    num_unique_labels = len(unique_labels)\n",
    "    print(\"Количество уникальных меток:\", num_unique_labels)\n",
    "    return sentences, labels, num_unique_labels\n",
    "\n",
    "def prepare_data(tokenizer, sentences, labels):\n",
    "    tokenized_input = tokenizer(sentences.tolist(), is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True, max_length=128)\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_flatten = [item for sublist in labels for item in sublist]\n",
    "    label_encoder.fit(labels_flatten)\n",
    "    labels_encoded = [label_encoder.transform(label).tolist() for label in labels]\n",
    "    labels_aligned = align_labels_with_tokens(labels_encoded, tokenized_input)\n",
    "    return tokenized_input, labels_aligned, label_encoder\n",
    "\n",
    "def align_labels_with_tokens(labels, tokenized_input):\n",
    "    labels_aligned = []\n",
    "    for i, label in enumerate(labels):\n",
    "        word_ids = tokenized_input.word_ids(batch_index=i)\n",
    "        label_aligned = [-100 if word_id is None else label[word_id] for word_id in word_ids]\n",
    "        labels_aligned.append(label_aligned)\n",
    "    return labels_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a26be42-033e-49a7-a50b-3b051eb7ebe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:28:46.693983Z",
     "iopub.status.busy": "2024-04-17T16:28:46.693063Z",
     "iopub.status.idle": "2024-04-17T16:28:46.710996Z",
     "shell.execute_reply": "2024-04-17T16:28:46.709974Z",
     "shell.execute_reply.started": "2024-04-17T16:28:46.693939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenized_inputs, labels_aligned):\n",
    "        self.tokenized_inputs = tokenized_inputs\n",
    "        self.labels = labels_aligned\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_inputs.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "def train_model(model, train_loader, device, epochs=3):\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(model, train_loader, optimizer, device, scheduler)\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}')\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(data_loader, desc='Batch', leave=False)\n",
    "    for batch in progress_bar:\n",
    "        if 'offset_mapping' in batch:\n",
    "            del batch['offset_mapping']\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63cd215e-d71e-4848-a3bb-ad4e80b2c9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:28:46.714022Z",
     "iopub.status.busy": "2024-04-17T16:28:46.713384Z",
     "iopub.status.idle": "2024-04-17T16:28:46.728465Z",
     "shell.execute_reply": "2024-04-17T16:28:46.727373Z",
     "shell.execute_reply.started": "2024-04-17T16:28:46.713992Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48293f-c771-4aab-991a-349b025961f7",
   "metadata": {},
   "source": [
    "# Biobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82aa1ee8-1ad7-4dfe-829d-f69eee07f727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:28:46.730724Z",
     "iopub.status.busy": "2024-04-17T16:28:46.730Z",
     "iopub.status.idle": "2024-04-17T16:35:12.531365Z",
     "shell.execute_reply": "2024-04-17T16:35:12.530073Z",
     "shell.execute_reply.started": "2024-04-17T16:28:46.730693Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных меток: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.2563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.6610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.3198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.2212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.1213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertForTokenClassification, AdamW, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "data_path = \"processed_entities_tokenized.csv\"\n",
    "model_name = 'dmis-lab/biobert-v1.1'\n",
    "sentences, labels, num_unique_labels = load_and_prepare_data(data_path)\n",
    "tokenizer, model = prepare_model_and_tokenizer(model_name, num_unique_labels)\n",
    "tokenized_input, labels_aligned, label_encoder = prepare_data(tokenizer, sentences, labels)\n",
    "train_dataset = CustomDataset(tokenized_input, labels_aligned)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_model(model, train_loader, device, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76ddb190-4073-4a08-97ce-9092ee557318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:35:12.533757Z",
     "iopub.status.busy": "2024-04-17T16:35:12.533017Z",
     "iopub.status.idle": "2024-04-17T16:35:15.876957Z",
     "shell.execute_reply": "2024-04-17T16:35:15.875819Z",
     "shell.execute_reply.started": "2024-04-17T16:35:12.533726Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в without_anomalies_BIOBERT_model\n",
      "Токенизатор сохранен в without_anomalies_BIOBERT_tokenizer\n"
     ]
    }
   ],
   "source": [
    "def save_model_and_tokenizer(model, tokenizer, model_path, tokenizer_path):\n",
    "    model.save_pretrained(model_path)\n",
    "    tokenizer.save_pretrained(tokenizer_path)\n",
    "    print(f\"Модель сохранена в {model_path}\")\n",
    "    print(f\"Токенизатор сохранен в {tokenizer_path}\")\n",
    "\n",
    "model_path = \"without_anomalies_BIOBERT_model\"\n",
    "tokenizer_path = \"without_anomalies_BIOBERT_tokenizer\"\n",
    "\n",
    "save_model_and_tokenizer(model, tokenizer, model_path, tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cfd88-280e-4735-9185-7d9a5bb91d52",
   "metadata": {},
   "source": [
    "# Pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31dd15a8-54fe-4f37-a106-6f1c75957394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:35:15.879110Z",
     "iopub.status.busy": "2024-04-17T16:35:15.878300Z",
     "iopub.status.idle": "2024-04-17T16:41:53.779656Z",
     "shell.execute_reply": "2024-04-17T16:41:53.777506Z",
     "shell.execute_reply.started": "2024-04-17T16:35:15.879078Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных меток: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.5752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.4036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.2794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.0989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "data_path = \"processed_entities_tokenized.csv\"\n",
    "model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\" \n",
    "sentences, labels, num_unique_labels = load_and_prepare_data(data_path)\n",
    "tokenizer, model = prepare_model_and_tokenizer(model_name, num_unique_labels)\n",
    "tokenized_input, labels_aligned, label_encoder = prepare_data(tokenizer, sentences, labels)\n",
    "train_dataset = CustomDataset(tokenized_input, labels_aligned)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_model(model, train_loader, device, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "396e7bd4-32de-437c-a6b9-74c0d037b5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T16:41:53.782071Z",
     "iopub.status.busy": "2024-04-17T16:41:53.781159Z",
     "iopub.status.idle": "2024-04-17T16:41:56.789608Z",
     "shell.execute_reply": "2024-04-17T16:41:56.788488Z",
     "shell.execute_reply.started": "2024-04-17T16:41:53.782013Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в without_anomalies_PUBMEDBERT_model\n",
      "Токенизатор сохранен в without_anomalies_PUBMEDBERT_tokenizer\n"
     ]
    }
   ],
   "source": [
    "def save_model_and_tokenizer(model, tokenizer, model_path, tokenizer_path):\n",
    "    model.save_pretrained(model_path)\n",
    "    tokenizer.save_pretrained(tokenizer_path)\n",
    "    print(f\"Модель сохранена в {model_path}\")\n",
    "    print(f\"Токенизатор сохранен в {tokenizer_path}\")\n",
    "\n",
    "model_path = \"without_anomalies_PUBMEDBERT_model\"\n",
    "tokenizer_path = \"without_anomalies_PUBMEDBERT_tokenizer\"\n",
    "\n",
    "save_model_and_tokenizer(model, tokenizer, model_path, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c67f7ab4-a268-4a84-a128-0417de5ace67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T17:25:29.439644Z",
     "iopub.status.busy": "2024-04-09T17:25:29.438513Z",
     "iopub.status.idle": "2024-04-09T17:25:29.488038Z",
     "shell.execute_reply": "2024-04-09T17:25:29.486908Z",
     "shell.execute_reply.started": "2024-04-09T17:25:29.439608Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: O\n",
      "a: O\n",
      "20: B-Age\n",
      "-: I-Age\n",
      "year: I-Age\n",
      "-: I-Age\n",
      "old: I-Age\n",
      "woman: B-Sex\n",
      "was: O\n",
      "diagnosed: B-Clinical_event\n",
      "with: O\n",
      "breast: B-Disease_disorder\n",
      "cancer: I-Disease_disorder\n",
      "[SEP]: O\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "text = \"A 20-year-old woman was diagnosed with breast cancer\"\n",
    "\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "predicted_label_indices = predictions.squeeze().cpu().numpy()\n",
    "predicted_labels = [label_encoder.inverse_transform([idx])[0] for idx in predicted_label_indices]\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].cpu())\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2492e876-7a59-4820-8f52-fbb561e94d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T17:26:00.078918Z",
     "iopub.status.busy": "2024-04-09T17:26:00.077935Z",
     "iopub.status.idle": "2024-04-09T17:26:00.147447Z",
     "shell.execute_reply": "2024-04-09T17:26:00.146272Z",
     "shell.execute_reply.started": "2024-04-09T17:26:00.078876Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"A 28-year-old previously healthy man presented with a 6-week history of palpitations. The symptoms occurred during rest, 2–3 times per week, lasted up to 30 minutes at a time and were associated with dyspnea.Except for a grade 2/6 holosystolic tricuspid regurgitation murmur (best heard at the left sternal border with inspiratory accentuation), physical examination yielded unremarkable findings.An electrocardiogram (ECG) revealed normal sinus rhythm and a Wolff– Parkinson– White pre-excitation pattern (Fig.1: Top), produced by a right-sided accessory pathway.Transthoracic echocardiography demonstrated the presence of Ebstein's anomaly of the tricuspid valve, with apical displacement of the valve and formation of an “atrialized” right ventricle (a functional unit between the right atrium and the inlet [inflow] portion of the right ventricle) (Fig.2).The anterior tricuspid valve leaflet was elongated (Fig.2C, arrow), whereas the septal leaflet was rudimentary (Fig.2C, arrowhead).Contrast echocardiography using saline revealed a patent foramen ovale with right-to-left shunting and bubbles in the left atrium (Fig.2D).The patient underwent an electrophysiologic study with mapping of the accessory pathway, followed by radiofrequency ablation (interruption of the pathway using the heat generated by electromagnetic waves at the tip of an ablation catheter).His post-ablation ECG showed a prolonged PR interval and an odd “second” QRS complex in leads III, aVF and V2–V4 (Fig.1Bottom), a consequence of abnormal impulse conduction in the “atrialized” right ventricle.The patient reported no recurrence of palpitations at follow-up 6 months after the ablation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b8c76ea-51ee-4d43-ba3e-aa2e8c25c082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T17:26:00.977355Z",
     "iopub.status.busy": "2024-04-09T17:26:00.976302Z",
     "iopub.status.idle": "2024-04-09T17:26:01.091101Z",
     "shell.execute_reply": "2024-04-09T17:26:01.089743Z",
     "shell.execute_reply.started": "2024-04-09T17:26:00.977304Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: O\n",
      "a: O\n",
      "28: B-Age\n",
      "-: I-Age\n",
      "year: I-Age\n",
      "-: I-Age\n",
      "old: I-Age\n",
      "previously: B-History\n",
      "healthy: I-History\n",
      "man: B-Sex\n",
      "presented: B-Clinical_event\n",
      "with: O\n",
      "a: O\n",
      "6: B-Duration\n",
      "-: I-Duration\n",
      "week: I-Duration\n",
      "history: O\n",
      "of: O\n",
      "palp: B-Sign_symptom\n",
      "##itations: B-Sign_symptom\n",
      ".: O\n",
      "the: O\n",
      "symptoms: B-Sign_symptom\n",
      "occurred: O\n",
      "during: O\n",
      "rest: B-Activity\n",
      ",: O\n",
      "2: B-Frequency\n",
      "[UNK]: I-Frequency\n",
      "3: I-Frequency\n",
      "times: I-Frequency\n",
      "per: I-Frequency\n",
      "week: I-Frequency\n",
      ",: O\n",
      "lasted: O\n",
      "up: B-Detailed_description\n",
      "to: I-Detailed_description\n",
      "30: I-Detailed_description\n",
      "minutes: I-Detailed_description\n",
      "at: I-Detailed_description\n",
      "a: I-Detailed_description\n",
      "time: I-Detailed_description\n",
      "and: O\n",
      "were: O\n",
      "associated: O\n",
      "with: O\n",
      "dyspnea: B-Sign_symptom\n",
      ".: O\n",
      "except: O\n",
      "for: O\n",
      "a: O\n",
      "grade: B-Lab_value\n",
      "2: I-Lab_value\n",
      "/: I-Lab_value\n",
      "6: I-Lab_value\n",
      "holo: B-Detailed_description\n",
      "##s: B-Detailed_description\n",
      "##yst: B-Detailed_description\n",
      "##olic: B-Detailed_description\n",
      "tricuspid: B-Biological_structure\n",
      "regurgitation: B-Sign_symptom\n",
      "mur: I-Sign_symptom\n",
      "##mu: I-Sign_symptom\n",
      "##r: I-Sign_symptom\n",
      "(: O\n",
      "best: O\n",
      "heard: O\n",
      "at: O\n",
      "the: O\n",
      "left: B-Biological_structure\n",
      "sternal: I-Biological_structure\n",
      "border: I-Biological_structure\n",
      "with: O\n",
      "inspiratory: I-Detailed_description\n",
      "accent: I-Detailed_description\n",
      "##uation: I-Detailed_description\n",
      "): O\n",
      ",: O\n",
      "physical: B-Diagnostic_procedure\n",
      "examination: I-Diagnostic_procedure\n",
      "yielded: O\n",
      "unre: B-Lab_value\n",
      "##mark: B-Lab_value\n",
      "##able: B-Lab_value\n",
      "findings: O\n",
      ".: O\n",
      "an: O\n",
      "electrocardiogram: B-Diagnostic_procedure\n",
      "(: O\n",
      "ecg: B-Diagnostic_procedure\n",
      "): O\n",
      "revealed: O\n",
      "normal: B-Lab_value\n",
      "sinus: B-Diagnostic_procedure\n",
      "rhythm: I-Diagnostic_procedure\n",
      "and: O\n",
      "a: O\n",
      "wol: B-Sign_symptom\n",
      "##ff: B-Sign_symptom\n",
      "[UNK]: I-Sign_symptom\n",
      "parkinson: I-Sign_symptom\n",
      "[UNK]: I-Sign_symptom\n",
      "white: I-Sign_symptom\n",
      "pre: I-Sign_symptom\n",
      "-: I-Sign_symptom\n",
      "excitation: I-Sign_symptom\n",
      "pattern: I-Sign_symptom\n",
      "(: O\n",
      "fig: O\n",
      ".: O\n",
      "1: O\n",
      ":: O\n",
      "top: O\n",
      "): O\n",
      ",: O\n",
      "produced: O\n",
      "by: O\n",
      "a: O\n",
      "right: B-Detailed_description\n",
      "-: I-Detailed_description\n",
      "sided: I-Detailed_description\n",
      "accessory: B-Disease_disorder\n",
      "pathway: I-Disease_disorder\n",
      ".: O\n",
      "transthoracic: B-Biological_structure\n",
      "echocardiography: B-Diagnostic_procedure\n",
      "demonstrated: O\n",
      "[SEP]: O\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "predicted_label_indices = predictions.squeeze().cpu().numpy()\n",
    "predicted_labels = [label_encoder.inverse_transform([idx])[0] for idx in predicted_label_indices]\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].cpu())\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2603f9ba-2d61-4391-8a95-66fc0aa76f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T17:26:05.302694Z",
     "iopub.status.busy": "2024-04-09T17:26:05.301896Z",
     "iopub.status.idle": "2024-04-09T17:26:05.397176Z",
     "shell.execute_reply": "2024-04-09T17:26:05.395881Z",
     "shell.execute_reply.started": "2024-04-09T17:26:05.302641Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: O\n",
      "a: O\n",
      "28: B-Age\n",
      "-: O\n",
      "year: O\n",
      "-: O\n",
      "old: O\n",
      "previously: B-History\n",
      "healthy: O\n",
      "man: B-Sex\n",
      "presented: B-Clinical_event\n",
      "with: O\n",
      "a: O\n",
      "6: B-Duration\n",
      "-: O\n",
      "week: O\n",
      "history: O\n",
      "of: O\n",
      "palpitations: B-Sign_symptom\n",
      ".: O\n",
      "the: O\n",
      "symptoms: B-Sign_symptom\n",
      "occurred: O\n",
      "during: O\n",
      "rest: B-Activity\n",
      ",: O\n",
      "2: B-Frequency\n",
      "[UNK]: O\n",
      "3: O\n",
      "times: O\n",
      "per: O\n",
      "week: O\n",
      ",: O\n",
      "lasted: O\n",
      "up: B-Detailed_description\n",
      "to: O\n",
      "30: O\n",
      "minutes: O\n",
      "at: O\n",
      "a: O\n",
      "time: O\n",
      "and: O\n",
      "were: O\n",
      "associated: O\n",
      "with: O\n",
      "dyspnea: B-Sign_symptom\n",
      ".: O\n",
      "except: O\n",
      "for: O\n",
      "a: O\n",
      "grade: B-Lab_value\n",
      "2: O\n",
      "/: O\n",
      "6: O\n",
      "holosystolic: B-Detailed_description\n",
      "tricuspid: B-Biological_structure\n",
      "regurgitation: B-Sign_symptom\n",
      "murmur: O\n",
      "(: O\n",
      "best: O\n",
      "heard: O\n",
      "at: O\n",
      "the: O\n",
      "left: B-Biological_structure\n",
      "sternal: O\n",
      "border: O\n",
      "with: O\n",
      "inspiratory: O\n",
      "accentuation: O\n",
      "): O\n",
      ",: O\n",
      "physical: B-Diagnostic_procedure\n",
      "examination: O\n",
      "yielded: O\n",
      "unremarkable: B-Lab_value\n",
      "findings: O\n",
      ".: O\n",
      "an: O\n",
      "electrocardiogram: B-Diagnostic_procedure\n",
      "(: O\n",
      "ecg: B-Diagnostic_procedure\n",
      "): O\n",
      "revealed: O\n",
      "normal: B-Lab_value\n",
      "sinus: B-Diagnostic_procedure\n",
      "rhythm: O\n",
      "and: O\n",
      "a: O\n",
      "wolff: B-Sign_symptom\n",
      "[UNK]: O\n",
      "parkinson: O\n",
      "[UNK]: O\n",
      "white: O\n",
      "pre: O\n",
      "-: O\n",
      "excitation: O\n",
      "pattern: O\n",
      "(: O\n",
      "fig: O\n",
      ".: O\n",
      "1: O\n",
      ":: O\n",
      "top: O\n",
      "): O\n",
      ",: O\n",
      "produced: O\n",
      "by: O\n",
      "a: O\n",
      "right: B-Detailed_description\n",
      "-: O\n",
      "sided: O\n",
      "accessory: B-Disease_disorder\n",
      "pathway: O\n",
      ".: O\n",
      "transthoracic: B-Biological_structure\n",
      "echocardiography: B-Diagnostic_procedure\n",
      "demonstrated: O\n",
      "[SEP]: O\n"
     ]
    }
   ],
   "source": [
    "word_labels = []\n",
    "current_word = \"\"\n",
    "current_label = None\n",
    "\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    if token.startswith(\"##\"):\n",
    "        current_word += token[2:]\n",
    "    else:\n",
    "        if current_word:\n",
    "            word_labels.append((current_word, current_label))\n",
    "        current_word = token\n",
    "        current_label = label if label.startswith(\"B-\") else \"O\"\n",
    "\n",
    "if current_word:\n",
    "    word_labels.append((current_word, current_label))\n",
    "\n",
    "for word, label in word_labels:\n",
    "    print(f\"{word}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f933bfa-04b4-42a6-b89c-cc48776843ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T17:32:32.209157Z",
     "iopub.status.busy": "2024-04-09T17:32:32.207938Z",
     "iopub.status.idle": "2024-04-09T17:32:32.262904Z",
     "shell.execute_reply": "2024-04-09T17:32:32.261806Z",
     "shell.execute_reply.started": "2024-04-09T17:32:32.209101Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "word_labels = []\n",
    "current_word = \"\"\n",
    "current_label = None\n",
    "\n",
    "for token, label in zip(tokens, predicted_labels):\n",
    "    if token.startswith(\"##\"):\n",
    "        current_word += token[2:]\n",
    "    else:\n",
    "        if current_word:\n",
    "            word_labels.append((current_word, current_label))\n",
    "        current_word = token\n",
    "        current_label = label if label.startswith(\"B-\") else \"O\"\n",
    "\n",
    "if current_word:\n",
    "    word_labels.append((current_word, current_label))\n",
    "\n",
    "df_word_labels = pd.DataFrame(word_labels, columns=[\"Word\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "549e9a53-a8c7-476a-8a0b-12a6fffbe3f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T17:32:36.877598Z",
     "iopub.status.busy": "2024-04-09T17:32:36.876636Z",
     "iopub.status.idle": "2024-04-09T17:32:36.910003Z",
     "shell.execute_reply": "2024-04-09T17:32:36.908943Z",
     "shell.execute_reply.started": "2024-04-09T17:32:36.877543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>B-Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>transthoracic</td>\n",
       "      <td>B-Biological_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>echocardiography</td>\n",
       "      <td>B-Diagnostic_procedure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>demonstrated</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Word                   Label\n",
       "0               [CLS]                       O\n",
       "1                   a                       O\n",
       "2                  28                   B-Age\n",
       "3                   -                       O\n",
       "4                year                       O\n",
       "..                ...                     ...\n",
       "113                 .                       O\n",
       "114     transthoracic  B-Biological_structure\n",
       "115  echocardiography  B-Diagnostic_procedure\n",
       "116      demonstrated                       O\n",
       "117             [SEP]                       O\n",
       "\n",
       "[118 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600588fd-82fe-4dac-892d-9fe185495a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
